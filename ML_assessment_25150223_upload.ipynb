{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Assessment 2\n",
    "\n",
    "Through the following notebook, you will be tasked with **implementing** two different classification approaches: **k Nearest Neighbours** and **Decision Trees**. You will apply these to two different datasets, evaluate the produced models and analyse their performance.\n",
    "\n",
    "This will be done through several different tasks and sub-tasks:\n",
    "- [Dataset](#Dataset)\n",
    "    - [Task 1: Dataset statistics **(10\\%)**](#Task-1---Dataset-statistics)\n",
    "- [k Nearest Neigbours](#k-Nearest-Neigbours)\n",
    "    - [Task 2.1: Euclidean distance **(10\\%)**](#Task-2.1---Euclidean-distance)\n",
    "    - [Task 2.2: kNN classifier **(20\\%)**](#Task-2.2---kNN-classifier)\n",
    "- [Decision Trees](#Decision-Trees)\n",
    "    - [Task 3.1: Entropy and Information Gain **(10\\%)**](#Task-3.1---Entropy-and-Information-Gain)\n",
    "    - [Task 3.2: Decision Tree classifier **(30\\%)**](#Task-3.2---Decision-Tree-classifier)\n",
    "- [Model evaluation and analysis](#Model-evaluation-and-analysis)\n",
    "    - [Task 4.1: Evaluation **(10\\%)**](#Task-4.1---Evaluation)\n",
    "    - [Task 4.2: Analysis **(10\\%)**](#Task-4.2---Analysis)\n",
    "\n",
    "**Note:** The (%) noted above are out of 100; this will be scaled down to **maximum of 70 marks** for the assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this assessment, you will be working with two datasets:\n",
    "- A [numeric-only](#Numerical-data) dataset (crystal systems of Li-ion batteries)\n",
    "- A dataset with [mixed numeric and categorical](#Categorical-data) features (forest cover)\n",
    "\n",
    "For developing your solutions, **you have only been provided with a portion of the samples from each of the dataset** (70% of the [numeric-only](#Numerical-data) and 50% of the [mixed numeric and categorical](#Categorical-data) data). These will be in **identical format** to the full datasets used for evaluating your solutions (there will just be more samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data\n",
    "\n",
    "The main part of the assessment will be done on the dataset containing only numerical features describing the physical and chemical properties of the Li-ion battery, which can be classified on the basis of their crystal system. Three major classes of crystal systems are: _monoclinic_, _orthorhombic_ and _triclinic_. (The dataset for this assessment has been adapted from the full dataset which can be found [here](https://www.kaggle.com/datasets/divyansh22/crystal-system-properties-for-liion-batteries\n",
    "\n",
    "Each sample corresponds to the properties of a battery, and consists of following features:\n",
    "\n",
    "| Feature Name      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Formation Energy`       | `float`: eV | Formation energy of the material. |\n",
    "| `E Above Hull` | `float`: eV | Energy of decomposition of material into most stable ones. |\n",
    "| `Band Gap` | `float`: eV | Band gap. |\n",
    "| `Nsites` | `int`: count | Number of atoms in the unit cell of the crystal. |\n",
    "| `Density` | `float`: gm/cc | The density of bulk crystalline materials. |\n",
    "| `Volume` | `float` | The unit cell volume of the material. |\n",
    "\n",
    "The goal for the assessment is to predict whether the crystal system of the battery is _monoclinic_, _orthorhombic_ or _triclinic_, which provides a classification for each sample:\n",
    "\n",
    "| Class      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Crystal System`  | `string`: class designation | Class of the crystal system (three different values). |\n",
    "\n",
    "\n",
    "This dataset will be used for the developmet and testing of both the [kNN](#k-Nearest-Neigbours) and [Decision Tree](#Decision-Trees) classifier, as well as for the [evaluation](#Task-4.1---Evaluation) of both of the classification approaches.\n",
    "\n",
    "The following cell loads the dataset, and splits the samples randomly, using  $80\\%$ of samples for training and $20\\%$ for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset consists of 237 samples\n",
      "The numerical data loaded consists of following columns:\n",
      "\tColumn 0: Formation Energy\n",
      "\tColumn 1: E Above Hull\n",
      "\tColumn 2: Band Gap\n",
      "\tColumn 3: Nsites\n",
      "\tColumn 4: Density\n",
      "\tColumn 5: Volume\n",
      "\tColumn 6: Crystal System\n",
      "An example sample:\n",
      "\tFeature 0: Formation Energy=-2.555\n",
      "\tFeature 1: E Above Hull=0.069\n",
      "\tFeature 2: Band Gap=1.854\n",
      "\tFeature 3: Nsites=15\n",
      "\tFeature 4: Density=2.925\n",
      "\tFeature 5: Volume=179.798\n",
      "\tClass (Family): triclinic\n",
      "The training set consists of 189 samples and 189 associated ground truth classes\n",
      "The test set consists of 48 samples and 48 associated ground truth classes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import count\n",
    "\n",
    "numerical_data = pd.read_csv(r'batteries.csv')\n",
    "\n",
    "print(\"The dataset consists of {} samples\".format(len(numerical_data)))\n",
    "print(\"The numerical data loaded consists of following columns:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tColumn {}: {}\".format(i, x) for i, x in enumerate(numerical_data.columns)])))\n",
    "print(\"An example sample:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tFeature {}: {}={}\".format(i, x, v) for i, (x, v) in \n",
    "               enumerate(zip(numerical_data.columns, numerical_data.loc[0, :])) if not x == 'Crystal System'])))\n",
    "print('\\tClass (Family): {}'.format(numerical_data.loc[0, 'Crystal System']))\n",
    "\n",
    "# We split the dataset into features and the target class, using the 'Family' column as the target:\n",
    "X_nd = numerical_data.loc[:, numerical_data.columns!='Crystal System'].values\n",
    "y_nd = numerical_data['Crystal System'].values\n",
    "\n",
    "# We further split the dataset into a training and testing set\n",
    "X_nd_train, X_nd_test, y_nd_train, y_nd_test = train_test_split(X_nd, y_nd, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"The training set consists of {} samples and {} associated ground truth classes\".format(len(X_nd_train),\n",
    "                                                                                             len(y_nd_train)))\n",
    "print(\"The test set consists of {} samples and {} associated ground truth classes\".format(len(X_nd_test),\n",
    "                                                                                             len(y_nd_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data\n",
    "\n",
    "The second dataset for this assessment contains a mix of numerical and categorical features, with the goal of predicting the forest cover type. The data used in this assessment is adapted from a full dataset provided [here](https://archive.ics.uci.edu/ml/datasets/Covertype) (Jock A. Blackard and Colorado State University).\n",
    "\n",
    "Each sample corresponds to a 30x30 meter cell, and consists of cartographic variables only (i.e. it does not rely on any remotely sensed imaging data), derived from from US Geological Survey (USGS) and USFS data. Each sample consists of the following features (categorical features can be distinguished by being encoded as a string rather tha a numer):\n",
    "\n",
    "| Feature Name      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Elevation`       | `float`: kilometers | Elevation |\n",
    "| `Aspect`   | `int`: degrees azimut | Aspect in degreez azimuth |\n",
    "| `Slope`      | `int`: degrees | Slope in degrees |\n",
    "| `Horizontal_Distance_To_Hydrology`   | `float`: kilometers | Horiz. distance to nearest surface water feature        |\n",
    "| `Vertical_Distance_To_Hydrology`   | `float`: kilometers | Vert. distance to nearest surface water feature        |\n",
    "| `Horizontal_Distance_To_Roadways`     | `float`: kilometers | Hor. distance to nearest roadway       |\n",
    "| `Hillshade_9am`   |`int`: $0 \\dots 255 $|  Hillshade index at 9am, summer solstice        |\n",
    "| `Hillshade_Noon`      |`int`: $0 \\dots 255 $| Hillshade index at noon, summer solstice       |\n",
    "| `Hillshade_3pm`   |`int`: $0 \\dots 255 $| Hillshade index at 3pm, summer solstice        |\n",
    "| `Horizontal_Distance_To_Fire_Points`  | `float`: kilometers | Horiz. distance to nearest wildfire ignition point        |\n",
    "| `Wilderness_Area`   | `string`: name | Wilderness area name (4 different values)       |\n",
    "| `Soil_Type`   |`string`: code| Soil type code (40 different values)       |\n",
    "\n",
    "The goal of this dataset is to predict the forrest cover type for each 30x30 meter cell. A class, corresponding to the forest cover type, is associated to each sample:\n",
    "\n",
    "| Class      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Cover_Type`       | `string`: name | Forest cover type designation (7 different values). |\n",
    "\n",
    "\n",
    "**Note:** Tackling the categorical dataset is a **stretch task** for this assessment. It will be used in the development and testing of the [Decision Tree](#Decision-Trees) classifier, as well as for their [evaluation](#Task-4.1---Evaluation). Tackling this data will **require you to implement a** `DecisionTree` **from scratch**, as `sklearn` **does not provide this functionality**.\n",
    "\n",
    "The following cell loads the dataset, and splits the samples randomly, using  $80\\%$ of samples for training and $20\\%$ for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset consists of 58101 samples\n",
      "The numerical data loaded consists of following columns:\n",
      "\tColumn 0: Elevation\n",
      "\tColumn 1: Aspect\n",
      "\tColumn 2: Slope\n",
      "\tColumn 3: Horizontal_Distance_To_Hydrology\n",
      "\tColumn 4: Vertical_Distance_To_Hydrology\n",
      "\tColumn 5: Horizontal_Distance_To_Roadways\n",
      "\tColumn 6: Hillshade_9am\n",
      "\tColumn 7: Hillshade_Noon\n",
      "\tColumn 8: Hillshade_3pm\n",
      "\tColumn 9: Horizontal_Distance_To_Fire_Points\n",
      "\tColumn 10: Wilderness_Area\n",
      "\tColumn 11: Soil_Type\n",
      "\tColumn 12: Cover_Type\n",
      "An example sample:\n",
      "\tFeature 0: Elevation=3.0\n",
      "\tFeature 1: Aspect=87.0\n",
      "\tFeature 2: Slope=9.0\n",
      "\tFeature 3: Horizontal_Distance_To_Hydrology=0.3\n",
      "\tFeature 4: Vertical_Distance_To_Hydrology=0.0\n",
      "\tFeature 5: Horizontal_Distance_To_Roadways=3.7\n",
      "\tFeature 6: Hillshade_9am=233.0\n",
      "\tFeature 7: Hillshade_Noon=226.0\n",
      "\tFeature 8: Hillshade_3pm=125.0\n",
      "\tFeature 9: Horizontal_Distance_To_Fire_Points=2.2\n",
      "\tFeature 10: Wilderness_Area=Rawah\n",
      "\tFeature 11: Soil_Type=ELU-7745\n",
      "\tClass (Cover_Type): Lodgepole_Pine\n",
      "The training set consists of 46480 samples and 46480 associated ground truth classes\n",
      "The test set consists of 11621 samples and 11621 associated ground truth classes\n"
     ]
    }
   ],
   "source": [
    "categorical_data = pd.read_csv(r'forestcover.csv')\n",
    "\n",
    "print(\"The dataset consists of {} samples\".format(len(categorical_data)))\n",
    "print(\"The numerical data loaded consists of following columns:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tColumn {}: {}\".format(i, x) for i, x in enumerate(categorical_data.columns)])))\n",
    "print(\"An example sample:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tFeature {}: {}={}\".format(i, x, v) for i, (x, v) in \n",
    "               enumerate(zip(categorical_data.columns, categorical_data.loc[0, :])) if not x == 'Cover_Type'])))\n",
    "print('\\tClass (Cover_Type): {}'.format(categorical_data.loc[0, 'Cover_Type']))\n",
    "\n",
    "# We split the dataset into features and the target class, using the 'Cover_Type' column as the target:\n",
    "X_cd = categorical_data.loc[:, categorical_data.columns!='Cover_Type'].values\n",
    "y_cd = categorical_data['Cover_Type'].values\n",
    "\n",
    "\n",
    "# We further split the dataset into a training and testing set\n",
    "X_cd_train, X_cd_test, y_cd_train, y_cd_test = train_test_split(X_cd, y_cd, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"The training set consists of {} samples and {} associated ground truth classes\".format(len(X_cd_train),\n",
    "                                                                                             len(y_cd_train)))\n",
    "print(\"The test set consists of {} samples and {} associated ground truth classes\".format(len(X_cd_test),\n",
    "                                                                                             len(y_cd_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Dataset statistics\n",
    "#### 10% marks\n",
    "\n",
    "To handle the data for the classification tasks, implement functions that will assist in querying some basic information about the dataset you are handling.\n",
    "\n",
    "Given a set of M samples $\\mathbf{x} = \\{\\mathbf{x}_i\\} \\forall i=1..M$ with n features each $\\mathbf{x}_i = \\{x_{1,i}, \\dots, x_{n,i}\\}$, and the corresponding ground truth labels $\\mathbf{y} = \\{y_i\\} \\forall i=1..M$, implement two functions:\n",
    "\n",
    "- `class_probabilities(y)` : calcualtes the class probabilities from the list of ground truth labels\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `y`: The list of ground truth labels for a dataset<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    A dictionary of class labels and their probabilities (i.e. the frequency of that class in the dataset)\n",
    "\n",
    "    *Example* :\n",
    "    ```python\n",
    "    y = [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
    "    print(class_probabilities(y))\n",
    "    ```\n",
    "    *Example output*:<br>\n",
    "    `{0: 0.3, 1: 0.5, 2: 0.2}`\n",
    "    \n",
    "    *Note:* Python dictionaries are unordered, so running this example might result in a different order of keys in the output, for example: `{2: 0.2, 0: 0.3, 1: 0.5}`<br><br>\n",
    "   \n",
    "- `most_common_class` : finds the most common class from the list of ground truth class labels.\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `y`: the list of ground truth labels for a dataset<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    the label of the most common class represented in the dataset.\n",
    "    \n",
    "    *Example*:\n",
    "    ```python\n",
    "    y = [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
    "    print(most_common_class(y))\n",
    "    ```\n",
    "    *Example output*:<br>\n",
    "    `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_probabilities(y):\n",
    "    total = 0\n",
    "    probs = []\n",
    "    \n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    count_dict = dict(zip(unique, counts))\n",
    "    counted_values = count_dict.values()\n",
    "    \n",
    "    for i in counted_values:\n",
    "        total += i\n",
    "    \n",
    "    for i in counted_values:\n",
    "        probs.append(i/total)\n",
    "    \n",
    "    return dict(zip(unique, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_common_class(y):\n",
    "    counter = Counter(y)\n",
    "    value = counter.most_common(1)[0][0]\n",
    "        \n",
    "    return value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique class labels and counts from numerical-only dataset: monoclinic: 92 orthorhombic: 89 triclinic: 56\n",
      "All classes and their probabilities:\n",
      "\tmonoclinic: 0.3881856540084388\n",
      "\torthorhombic: 0.3755274261603376\n",
      "\ttriclinic: 0.23628691983122363\n",
      "Most common class in the numerical-only dataset: monoclinic\n",
      "\n",
      "\n",
      "All unique class labels for the numerical-only training set: monoclinic: 76 orthorhombic: 69 triclinic: 44\n",
      "All classes and their probabilities (num-only training set):\n",
      "\tmonoclinic: 0.4021164021164021\n",
      "\torthorhombic: 0.36507936507936506\n",
      "\ttriclinic: 0.2328042328042328\n",
      "Most common class in the num-only training set: monoclinic\n",
      "\n",
      "\n",
      "All unique class labels for the numerical-only testing set: monoclinic: 16 orthorhombic: 20 triclinic: 12\n",
      "All classes and their probabilities (num-only tests set):\n",
      "\tmonoclinic: 0.3333333333333333\n",
      "\torthorhombic: 0.4166666666666667\n",
      "\ttriclinic: 0.25\n",
      "Most common class in the num-only test set: orthorhombic\n",
      "\n",
      "\n",
      "All class labels for a toy set: [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
      "All classses and their probabilities for the toy set:\n",
      "\t0: 0.3\n",
      "\t1: 0.5\n",
      "\t2: 0.2\n",
      "Most common class in the toy set: 1\n",
      "\n",
      "\n",
      "All classes and their probabilities from the categorical dataset:\n",
      "\tAspen: 0.017\n",
      "\tCottonwood/Willow: 0.005\n",
      "\tDouglas-fir: 0.029\n",
      "\tKrummholz: 0.035\n",
      "\tLodgepole_Pine: 0.486\n",
      "\tPonderosa_Pine: 0.062\n",
      "\tSpruce/Fir: 0.367\n",
      "Most common class in the categorical dataset: Lodgepole_Pine\n"
     ]
    }
   ],
   "source": [
    "unq, cnt = np.unique(y_nd, return_counts=True)\n",
    "print(\"All unique class labels and counts from numerical-only dataset: {}\".format(\n",
    "    ' '.join(['{}: {}'.format(v,c) for v, c in zip(unq, cnt)])))\n",
    "print(\"All classes and their probabilities:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_nd).items()])))\n",
    "print(\"Most common class in the numerical-only dataset: {}\".format(most_common_class(y_nd)))\n",
    "print(\"\\n\")\n",
    "\n",
    "unq, cnt = np.unique(y_nd_train, return_counts=True)\n",
    "print(\"All unique class labels for the numerical-only training set: {}\".format(\n",
    "    ' '.join(['{}: {}'.format(v,c) for v, c in zip(unq, cnt)])))\n",
    "print(\"All classes and their probabilities (num-only training set):\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_nd_train).items()])))\n",
    "print(\"Most common class in the num-only training set: {}\".format(most_common_class(y_nd_train)))\n",
    "print(\"\\n\")\n",
    "\n",
    "unq, cnt = np.unique(y_nd_test, return_counts=True)\n",
    "print(\"All unique class labels for the numerical-only testing set: {}\".format(\n",
    "    ' '.join(['{}: {}'.format(v,c) for v, c in zip(unq, cnt)])))\n",
    "print(\"All classes and their probabilities (num-only tests set):\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_nd_test).items()])))\n",
    "print(\"Most common class in the num-only test set: {}\".format(most_common_class(y_nd_test)))\n",
    "print(\"\\n\")\n",
    "\n",
    "y_test = [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
    "print(\"All class labels for a toy set: {}\".format(y_test))\n",
    "print(\"All classses and their probabilities for the toy set:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_test).items()])))\n",
    "print(\"Most common class in the toy set: {}\".format(most_common_class(y_test)))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"All classes and their probabilities from the categorical dataset:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {:.3f}\".format(c, p) for c, p in class_probabilities(y_cd).items()])))\n",
    "print(\"Most common class in the categorical dataset: {}\".format(most_common_class(y_cd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k Nearest Neighbours\n",
    "\n",
    "For the first part of the assessment, you are required to implement **k Nearest Neigbours**. A key concept for kNN (and many different machine learning algorithms) is that of **distance**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 - Euclidean distance\n",
    "#### 10% marks\n",
    "\n",
    "One of the most commonly used distance metrics is the Euclidean distance. The Euclidean distance between two points in the Euclidean space (also known as $L_2$ norm) is defined as the length of the line segment between those two points. For example, if we have two points in 2D space (i.e. two samples consisting of two features), $\\mathbf{x}_0 = \\{x_{0,0}, x_{0,1}\\}$ and $\\mathbf{x}_1 = \\{x_{1,0}, x_{1,1}\\}$, we can calculate the distance as:\n",
    "\n",
    "\\begin{equation*}\n",
    "d_{\\texttt{Euclidean}} = \\sqrt{(x_{0,0} - x_{1,0})^2 + (x_{0,1} - x_{1,1})^2}\n",
    "\\end{equation*}\n",
    "\n",
    "In other words, we need to calculate the difference between the first features of the two samples, the difference between the second features of the two samples, then square each of the differences, sum those squares, and calculate the square root of the resulting sum.\n",
    "\n",
    "In general, when we are dealing with points in nD space (corresponding to samples with n features) of the form $\\mathbf{x}_i = \\{x_{0,i}, x_{1,i}, \\dots, x_{n,i}\\}$, the procedure is very similar. To calculade the Euclidean disatnce, you need to calculate the difference between the corresponding features of two samples, square each of the differences, and calculate the square root of the resulting sum:\n",
    "\n",
    "\\begin{equation*}\n",
    "d_{\\texttt{Euclidean}} = \\sqrt{\\sum_i{(x_{0,i} - x_{1,i})^2}}\n",
    "\\end{equation*}\n",
    "\n",
    "Implement the Euclidean distance as a Python function:\n",
    "- `euclidean_distance`: calculates the Euclidean distance between two n-dimensional samples\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `x1`: An n-dimensional sample. This either a list of length $n$, or a `numpy.array` of dimensions `(n,)`<br>\n",
    "    `x2`: An n-dimensional sample. This either a list of length $n$, or a `numpy.array` of dimensions `(n,)`<br>\n",
    "\n",
    "    *Returns*<br>\n",
    "    The Euclidean distance between `x1` and `x2`.<br>\n",
    "    \n",
    "    *Example:*\n",
    "\n",
    "    ```python\n",
    "    x1 = [7, -1]\n",
    "    x2 = [4, 3]\n",
    "    print(euclidean_distance(x1, x2)\n",
    "    ```\n",
    "    *Example output:*<br>\n",
    "    `5.0`\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "                \n",
    "    indexCount = 0\n",
    "    sum2Total = 0\n",
    "    \n",
    "    # Do basic euclidean distance calulations...\n",
    "    while len(x1) >= indexCount+1:\n",
    "        sum1 = (x1[indexCount])-(x2[indexCount])\n",
    "        sum2 = sum1**2\n",
    "        sum2Total += sum2\n",
    "        indexCount += 1\n",
    "    \n",
    "    total = math.sqrt(sum2Total) # Square root the previous answer\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between [7, -1] (2D) and [4, 3] (2D) is 5.0\n",
      "Euclidean distance between [1, 2] (2D) and [3, 4] (2D) is 2.828\n",
      "Euclidean distance between [4.2, 3.6, 1.0] (3D) and [5.7, 2.8, -1.5] (3D) is 3.023\n",
      "Euclidean distance between [0.85482267 0.40564757 0.94674199 0.85549943 0.51001134 0.83035953\n",
      " 0.83923231 0.2073979  0.24238058 0.4768507  0.02595302 0.28598927\n",
      " 0.52015509 0.26223177 0.18784623 0.18100791 0.90145414 0.27575251\n",
      " 0.65664071 0.09788702] (20D) and [0.49455381 0.05515067 0.65754708 0.97441117 0.07286586 0.85886012\n",
      " 0.06526104 0.5217508  0.63610938 0.81093255 0.80790539 0.15365555\n",
      " 0.09360157 0.29316634 0.95481061 0.61790002 0.9420323  0.23216898\n",
      " 0.21347604 0.99136821] (20D) is 2.024\n"
     ]
    }
   ],
   "source": [
    "a = [7, -1]\n",
    "b = [4, 3]\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))\n",
    "a = [1, 2]\n",
    "b = [3, 4]\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {:.3f}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))\n",
    "a = [4.2, 3.6, 1.0]\n",
    "b = [5.7, 2.8, -1.5]\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {:.3f}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))\n",
    "a = np.random.rand(20)\n",
    "b = np.random.rand(20)\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {:.3f}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 - kNN classifier\n",
    "#### 20% marks\n",
    "\n",
    "K nearest neighbours classifier will predict the class of a sample based on the class label of its $k$ nearest neigbours, according to a given distance metric. Implement `kNN` classifier which works on samples with numerical features, and relies on the Euclidean distance, as a Python class implementing the following member functions:\n",
    "\n",
    "- `__init__(self, k = 5, distance = euclidean_distance)`: class constructor\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `k` : The number of neigbours to be considered by the classification model <br>\n",
    "    `distance`: Tunction which is used to calculate the distance between samples (you will use the Euclidean distance implemented in the previous task)<br><br>\n",
    "    \n",
    "- `fit(self, X, y)`: member function used to train the classifier (fit the model to the data)\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The dataset samples. This is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, n)`<br>\n",
    "    `y`: The dataset labels. This is either a list of length $M$, or a `numpy.array` of dimensions `(M,)`<br><br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    The trained classifier model.<br><br>\n",
    "    \n",
    "- `predict(self, X)`: member function used to predict the classes of samples `X`\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The samples for which to predict a class. If this is a single sample, then `X` is either a list of length $n$, or a `numpy.array` of dimensions `(n,)`. If this is a set of samples, then `X` is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, N)`<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    Predicted class for the samples of X. If `X` was a single sample, then the output is a single class label. If `X` was a set of samples, then the output is a `numpy.array` of dimensions `(n,`)<br>\n",
    "    \n",
    "    *Note:*<br>\n",
    "    The provided code outline already handles the case where `X` is a set of samples (by running on each sample separately). You need write the main logic of this function, i.e. calculating the prediction for a single sample.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn:\n",
    "    def __init__(self, k = 5, distance = euclidean_distance):\n",
    "        \n",
    "        self.k = k\n",
    "        self.distance = distance\n",
    "       \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "        return self # this should probably be the last line in your fit function\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        # the fololwing block of code handles lists/arrays containing multiple samples\n",
    "        X = np.array(X)\n",
    "        if len(X.shape) >= 2:\n",
    "            return np.array([self.predict(x) for x in X])\n",
    "        \n",
    "        # in the following section, you can assume that X is a single n-dimensional sample:\n",
    "        self.X = X\n",
    "        \n",
    "        distances = []\n",
    "        votes = []\n",
    "        finalOutput = []\n",
    "        \n",
    "        from collections import Counter\n",
    "        \n",
    "        # Calculate distances for each node\n",
    "        for i in range(len(self.X_train)):\n",
    "            dist = self.distance(self.X_train[i], self.X)\n",
    "            distances.append([dist, i])\n",
    "            \n",
    "        distances.sort() # Sort distances in ascending order\n",
    "        distances = distances[0:self.k]\n",
    "        \n",
    "        for distances, j in distances:\n",
    "            votes.append(self.y_train[j])\n",
    "        \n",
    "        answer = Counter(votes).most_common(1)[0][0] # Calculate the nearest neighbour...\n",
    "        finalOutput.append(answer) # ...and make it the result to be returned\n",
    "        \n",
    "        \n",
    "\n",
    "        return finalOutput\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: [-2.45500e+00  7.00000e-02  2.34400e+00  2.60000e+01  3.21300e+00\n",
      "  3.09993e+02]\n",
      "\tPredicted class: ['triclinic']\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.35200e+00  8.30000e-02  1.36700e+00  2.80000e+01  2.93500e+00\n",
      "  3.57496e+02]\n",
      "\tPredicted class: ['monoclinic']\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.55300e+00  7.30000e-02  2.64900e+00  3.20000e+01  2.87700e+00\n",
      "  3.73622e+02]\n",
      "\tPredicted class: ['monoclinic']\n",
      "\tTrue class: monoclinic\n",
      "Sample: [-2.43900e+00  5.70000e-02  2.30000e-01  1.50000e+01  3.02400e+00\n",
      "  1.77312e+02]\n",
      "\tPredicted class: ['triclinic']\n",
      "\tTrue class: triclinic\n",
      "Sample: [-2.88700e+00  4.00000e-02  3.14400e+00  5.20000e+01  2.69000e+00\n",
      "  6.79101e+02]\n",
      "\tPredicted class: ['orthorhombic']\n",
      "\tTrue class: monoclinic\n",
      "Sample: [-2.56400e+00  5.80000e-02  2.73000e+00  2.80000e+01  2.85600e+00\n",
      "  3.60121e+02]\n",
      "\tPredicted class: ['monoclinic']\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.91100e+00  6.40000e-02  3.07900e+00  3.40000e+01  2.63300e+00\n",
      "  4.31422e+02]\n",
      "\tPredicted class: ['triclinic']\n",
      "\tTrue class: triclinic\n"
     ]
    }
   ],
   "source": [
    "# Initialise the classifier with k=3 (using 9 neigbours)\n",
    "classifier = knn(k=9)\n",
    "# Fit the classifier to the training set\n",
    "classifier.fit(X_nd_train, y_nd_train)\n",
    "\n",
    "# Predict the classification for some samples to the testing set\n",
    "for (sample, prediction, truth) in zip(X_nd_test[3:10], classifier.predict(X_nd_test[3:10]), y_nd_test[3:10]):\n",
    "    # Print the sample, predicted class and ground truth\n",
    "    print(\"Sample: {}\\n\\tPredicted class: {}\\n\\tTrue class: {}\".format(sample, prediction, truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For the second part of the assignment, you are expected to implement a decision tree classifier. A decision tree models the data as a series of decisions based on the values of different features of the sample. The predictions are made in an interpretable fashion, where the decision is made by considering different sample features, and their values, until the new sample is grouped with similar samples presented during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1 - Entropy and Information Gain\n",
    "#### 10% marks\n",
    "\n",
    "Important concepts in decision trees are **entropy** and **information gain**. **Entropy** is a measure of the variance in the data, of how \"unpredictable\" the dataset is:\n",
    "\n",
    "- If a dataset consists only of samples with the same label (e.g. $\\{\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare\\}$), the entropy will be zero (the data is predictable).\n",
    "- If a dataset consists of an equal amount of samples from two classes, (e.g. $\\{\\blacksquare,\\triangle,\\triangle,\\blacksquare,\\triangle,\\blacksquare\\}$), the entropy will be one (the data is unpredictable).\n",
    "- If the class distribution in the dataset lies somewhere between these two extremes, the entropy will be between one and zero.\n",
    "- Entropy also increases as the number of different classes increases.\n",
    "\n",
    "Given $c$ classes, and their associated probabilities (frequencies) in the datasets, $p_i \\forall i \\in 0..c$, the entropy is calculated as:\n",
    "\n",
    "\\begin{equation*}\n",
    "E = -\\sum_i p_i log_2(p_i).\n",
    "\\end{equation*}\n",
    "\n",
    "Implement a function `entropy` which calculates the entropy of a set of class labels from the list of their associated probabilities:\n",
    "\n",
    "- `entropy(p_per_class)`: calculates the entropy of a set of class probabilities\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `p_per_class`: A list of $c$ probabilities, one for each class in the dataset. This either a list of length $c$, or a `numpy.array` of dimensions `(c,)`<br>\n",
    "\n",
    "    *Returns:*<br>\n",
    "    The entropy of a set with class probabilities given in `p_per_class`.<br>\n",
    "    \n",
    "    *Note:*<br>\n",
    "    You do not need to check if the list of probabilities given is correct; i.e. you may assume that all the probabilities in the list are strictly greater than zero, and that the sum of all the class probabilities equals one.\n",
    "    \n",
    "    *Example:*\n",
    "\n",
    "    ```python\n",
    "    probabilities = [0.5, 0.5]\n",
    "    print(entropy(probabilities))\n",
    "    ```\n",
    "    *Example output:*<br>\n",
    "    `1.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p_per_class):\n",
    "    y = np.array(p_per_class) # set y as a numpy array version of 'p_per_class'\n",
    "\n",
    "    return -np.sum([p * np.log2(p) for p in y])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of a set with only one class: -0.0\n",
      "Entropy of a set with two equally probable classes: 1.0\n",
      "Entropy of a set with four equally probable clasess: 2.0\n",
      "Entropy of a set with four classes with different probabilities: 1.846\n",
      "Entropy of the numerical (batteries) dataset: 1.552\n",
      "Entropy of the categorical (forest cover) dataset: 1.739\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy of a set with only one class: {}\".format(entropy([1.0])))\n",
    "print(\"Entropy of a set with two equally probable classes: {}\".format(entropy([0.5, 0.5])))\n",
    "print(\"Entropy of a set with four equally probable clasess: {}\".format(entropy([0.25, 0.25, 0.25, 0.25])))\n",
    "print(\"Entropy of a set with four classes with different probabilities: {:.3f}\".format(\n",
    "    entropy([0.2, 0.3, 0.4, 0.1])))\n",
    "print(\"Entropy of the numerical (batteries) dataset: {:.3f}\".format(\n",
    "    entropy(list(class_probabilities(y_nd).values()))))\n",
    "print(\"Entropy of the categorical (forest cover) dataset: {:.3f}\".format(\n",
    "    entropy(list(class_probabilities(y_cd).values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **information gain** describes how much variance was lost by dividing a set into parts, i.e. how much more \"predictable\" the parts are from the whole.\n",
    "\n",
    "For example, if we have a dataset $d=\\{\\blacksquare,\\triangle,\\triangle,\\blacksquare,\\triangle,\\blacksquare,\\triangle,\\blacksquare\\}$ (which is \"maximally unpredictable\", so we can calculate $E(d) = 1$), we can:\n",
    "- split it into $d_1=\\{\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare\\}$ and $d_2=\\{\\triangle, \\triangle, \\triangle, \\triangle\\}$.\n",
    "\n",
    "    Both of $d_1$ and $d_2$ are \"very predictable\" ($E(d_1) = E(d_2) = 0$), both subsets consist of one class only). The resulting information gain is large (we go from unpredictable to predictable, so we gain information):\n",
    "    \n",
    "    $I = E(d) - (0.5E(d_1) + 0.5E(d_2) = 1 - (0+0) =1$\n",
    "    \n",
    "- split it into $d_1=\\{\\blacksquare,\\triangle,\\triangle,\\blacksquare\\}$ and $d_2=\\{\\triangle,\\blacksquare,\\triangle,\\blacksquare\\}$.\n",
    "\n",
    "    Both of $d_1$ and $d_2$ are \"very unpredictable\" ($E(d_1) = E(d_2) = 1$), both subsets have the same amount of samples from each of the two classes). The resulting information gain is small (we start from an unpredictable dataset, and end with two unpredictable subsets, so we do not gain information):\n",
    "\n",
    "    $I = E(d) - (0.5E(d_1) + 0.5E(d_2) = 1 - (0.5\\times1+0.5\\times1) =0$\n",
    "    \n",
    "<br>\n",
    "In general, if we have a dataset $d$ containing $|d|$ samples, and we split it into $s$ subsets $d_i \\forall i=1..s$, each of size $|d_i|$, the information gain of this split is calculated as:\n",
    "\n",
    "\\begin{equation*}\n",
    "    I = E(d) - \\sum_{i=0}^s \\frac{|d_i|}{|d|}E(d_i)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2 - Decision Tree classifier\n",
    "#### 30% marks\n",
    "\n",
    "In each decision node of a decision tree, this classifier splits the dataset into two or more parts according to a value of a certain feature in the dataset.\n",
    "\n",
    "Given a set of M samples $\\mathbf{x} = \\{\\mathbf{x}_i\\} \\forall i=1..M$ with n features each $\\mathbf{x}_i = \\{x_{1,i}, \\dots, x_{n,i}\\}$, we could decide to split the dataset at the $j^{\\texttt{th}}$ (numerical) feature at value $v$. This would mean splitting the dataset into:\n",
    "- the subset $\\mathbf{x_{<}} = \\{\\mathbf{x}_i | x_{j,i} < v\\}$, which contains all the samples with the $j^{\\texttt{th}}$ smaller than $v$ and\n",
    "- the subset $\\mathbf{x_{\\geq}} = \\{\\mathbf{x}_i | x_{j,i} \\geq v\\}$, which contains all the samples with the $j^{\\texttt{th}}$ greater or equal than $v$.\n",
    "\n",
    "Similarly, we could decide to split a dataset at the $j^{\\texttt{th}}$ feature which is categorical. If the $j^{\\texttt{th}}$ feature of a sample $\\mathbf{x}_i$ can hold values $\\{\\texttt{child}, \\texttt{teen}, \\texttt{adult}\\}$, the resulting subsets would be:\n",
    "- the subset $\\mathbf{x_{\\texttt{child}}} = \\{\\mathbf{x}_i | x_{j,i} = \\texttt{child}\\}$, which contains all the samples with the feature $j^{\\texttt{th}}$ equal to $\\texttt{child}$, \n",
    "- the subset $\\mathbf{x_{\\texttt{teen}}} = \\{\\mathbf{x}_i | x_{j,i} = \\texttt{teen}\\}$, which contains all the samples with the feature $j^{\\texttt{th}}$ equal to $\\texttt{teen}$ and\n",
    "- the subset $\\mathbf{x_{\\texttt{adult}}} = \\{\\mathbf{x}_i | x_{j,i} = \\texttt{adult}\\}$, which contains all the samples with the feature $j^{\\texttt{th}}$ equal to $\\texttt{adult}$.\n",
    "\n",
    "In each node of the decision tree, the dataset is split according to the attribute $j$ which results in **the highest information gain** after the split. For categorical features, there is only one possible split (each category becomes a subset). For numerical features, it is neccessary to check all the possible values of split. For example, if the $j^{\\texttt{th}}$ in the dataset has appeared with the values of $\\{1, 1.5, 2.7, 3.2, 5\\}$, you need to calculate the information gain for splitting the dataset at $v=1.5$ (into $\\mathbf{x_{< 1.5}}$ and $\\mathbf{x_{\\geq 1.5}}$), $v=2.7$, $v=3.2$, $v=5$.\n",
    "\n",
    "The splitting continues until each node contains only samples of a single class, or a stopping criterion is reached. If a node contains training samples of more than one class, it returns the label of the majority (most probable) class as its decision.\n",
    "\n",
    "Implement a `DecisionTree` classifier which works on samples with both numerical and categorical features as a Python class implementing the following member functions:\n",
    "\n",
    "- `__init__(self, max_depth = -1, min_samples_per_node = 1)`: class constructor\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `max_dept` : The maximal depth of the tree (`max_depth == 0` corresponds to a decision tree with only the root node. `max_depth == -1` means no limit to the depth of the tree) <br>\n",
    "    `min_samples_per_node`: The minimal number of samples contained in a terminal (decision) node. If a split would cause one of the subsets to have less than `min_samples_per_node` samples, the split is not performed. <br><br>\n",
    "    \n",
    "- `fit(self, X, y)`: member function used to train the classifier (fit the model to the data)\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The dataset samples. This is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, n)`<br>\n",
    "    `y`: The dataset labels. This is either a list of length $M$, or a `numpy.array` of dimensions `(M,)`<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    The trained classifier model.<br><br>\n",
    "    \n",
    "- `predict(self, X)`: member function used to predict the classes of samples `X`\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The samples for which to predict a class. If this is a single sample, then `X` is either a list of length $n$, or a `numpy.array` of dimensions `(n,)`. If this is a set of samples, then `X` is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, N)`<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    Predicted class for the samples of X. If `X` was a single sample, then the output is a single class label. If `X` was a set of samples, then the output is a `numpy.array` of dimensions `(n,`)<br>\n",
    "    \n",
    "    *Note:*<br>\n",
    "    The provided code outline already handles the case where `X` is a set of samples (by running on each sample separately). You need write the main logic of this function, i.e. calculating the prediction for a single sample.<br><br>\n",
    "    \n",
    "*Note:* Your implementation will be tested in two parts. Firstly, it will be tested only on a dataset containing numerical values. Secondly, it will also be tested on a dataset containing a mix of categorical and numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# The following methods and implementations were inspired from GitHub (AssemblyAI-Examples, 2022) but altered by myself\n",
    "# to fit the rest of my code and function properly\n",
    "\n",
    "# Create a Node class to create instances of for the tree structure\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None,*,value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        \n",
    "        return self.value is not None\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth = -1, min_samples_per_node = 1):\n",
    "        self.min_samples_split = min_samples_per_node\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = None\n",
    "        self.root = None\n",
    "           \n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1], self.n_features)\n",
    "        self.root = self.grow_tree(X, y)\n",
    "        \n",
    "        return self # you may replace this line\n",
    "               \n",
    "    def predict(self, X):\n",
    "\n",
    "        # the fololwing block of code handles lists/arrays containing multiple samples\n",
    "        # !!!!! Tried to implement this code, but would create an error... !!!!!\n",
    "        #X = np.array(X)\n",
    "        #if len(X.shape) >= 2:\n",
    "            #return np.array([self.predict(x) for x in X])\n",
    "        \n",
    "        # in the following section, you can assume that X is a single n-dimensional sample:\n",
    "        return np.array([self.traverse_tree(x, self.root) for x in X])\n",
    "        \n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_feats = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # Check the stopping criteria\n",
    "        if (depth>=self.max_depth or n_labels==1 or n_samples<self.min_samples_split):\n",
    "            leaf_value = most_common_class(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_feats, self.n_features, replace=False)\n",
    "\n",
    "        # Find the best split\n",
    "        best_feature, best_thresh = self.best_split(X, y, feat_idxs)\n",
    "\n",
    "        # Create child nodes\n",
    "        left_idxs, right_idxs = self.split(X[:, best_feature], best_thresh)\n",
    "        left = self.grow_tree(X[left_idxs, :], y[left_idxs], depth+1)\n",
    "        right = self.grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n",
    "        \n",
    "        return Node(best_feature, best_thresh, left, right)\n",
    "    \n",
    "    # Calculate the best split\n",
    "    def best_split(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "\n",
    "            for thr in thresholds:\n",
    "                # Calculate the information gain\n",
    "                gain = self.information_gain(y, X_column, thr)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = thr\n",
    "\n",
    "        return split_idx, split_threshold\n",
    "    \n",
    "    # Information gain calculator\n",
    "    def information_gain(self, y, X_column, threshold):\n",
    "        # Parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "\n",
    "        # Create children\n",
    "        left_idxs, right_idxs = self.split(X_column, threshold)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Calculates the weighted average entropy of children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n",
    "\n",
    "        # Calculates the information gain\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        \n",
    "        return information_gain\n",
    "    \n",
    "    # Creates the split in the tree\n",
    "    def split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        \n",
    "        return left_idxs, right_idxs\n",
    "    \n",
    "    # Implementation of the earlier entropy funcion did not work here, and this implementation did not work for \n",
    "    # the function earlier\n",
    "    def _entropy(self, y):\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        prob = counts / len(y)\n",
    "        entropy = -np.sum(prob * np.log2(prob))\n",
    "        \n",
    "        return entropy\n",
    "    \n",
    "    # Works out how to traverse the tree structure if a node is able to\n",
    "    def traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        if type(x)==list or type(x)==np.ndarray :\n",
    "            if x[int(node.feature)] <= node.threshold:\n",
    "                return self.traverse_tree(x, node.left)\n",
    "        \n",
    "        return self.traverse_tree(x, node.right)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELLS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will test if the classifier implemented model can fit to the [numerical dataset](#Numerical-data), and predict solutions for some of the testing samples (this is not model evaluation yet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: [-2.45500e+00  7.00000e-02  2.34400e+00  2.60000e+01  3.21300e+00\n",
      "  3.09993e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.35200e+00  8.30000e-02  1.36700e+00  2.80000e+01  2.93500e+00\n",
      "  3.57496e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.55300e+00  7.30000e-02  2.64900e+00  3.20000e+01  2.87700e+00\n",
      "  3.73622e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: monoclinic\n",
      "Sample: [-2.43900e+00  5.70000e-02  2.30000e-01  1.50000e+01  3.02400e+00\n",
      "  1.77312e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: triclinic\n",
      "Sample: [-2.88700e+00  4.00000e-02  3.14400e+00  5.20000e+01  2.69000e+00\n",
      "  6.79101e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: monoclinic\n",
      "Sample: [-2.56400e+00  5.80000e-02  2.73000e+00  2.80000e+01  2.85600e+00\n",
      "  3.60121e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.91100e+00  6.40000e-02  3.07900e+00  3.40000e+01  2.63300e+00\n",
      "  4.31422e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: triclinic\n"
     ]
    }
   ],
   "source": [
    "# Initialise the classifier, requiring at least 3 samples in each node\n",
    "classifier = DecisionTree(min_samples_per_node = 3)\n",
    "# Fit the classifier to the training data\n",
    "classifier.fit(X_nd_train, y_nd_train)\n",
    "# Predict the classification for some samples to the testing set\n",
    "for (sample, prediction, truth) in zip(X_nd_test[3:10], classifier.predict(X_nd_test[3:10]), y_nd_test[3:10]):\n",
    "    # Print the sample, predicted class and ground truth\n",
    "    print(\"Sample: {}\\n\\tPredicted class: {}\\n\\tTrue class: {}\".format(sample, prediction, truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will check if the dataset is able to fit the model to the [dataset with mixed numerical and categorical values](#Categorical-data), and predict solutions for some of the testing samples (this is not model evaluation yet):\n",
    "\n",
    "_**Warning:**_ Executing this cell may take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: [2.4 48.0 11.0 0.0 0.0 0.4 224.0 215.0 123.0 1.3 'Cache_la_Poudre'\n",
      " 'ELU-2717']\n",
      "\tPredicted class: Ponderosa_Pine\n",
      "\tTrue class: Cottonwood/Willow\n",
      "Sample: [3.3 67.0 16.0 0.1 0.0 1.7 234.0 207.0 100.0 1.9 'Rawah' 'ELU-8772']\n",
      "\tPredicted class: Spruce/Fir\n",
      "\tTrue class: Spruce/Fir\n",
      "Sample: [3.3 60.0 15.0 0.1 -0.0 2.4 231.0 207.0 104.0 4.1 'Neota' 'ELU-8703']\n",
      "\tPredicted class: Spruce/Fir\n",
      "\tTrue class: Spruce/Fir\n",
      "Sample: [3.2 62.0 10.0 0.4 0.0 2.0 229.0 219.0 122.0 0.9 'Comanche_Peak'\n",
      " 'ELU-7755']\n",
      "\tPredicted class: Spruce/Fir\n",
      "\tTrue class: Spruce/Fir\n",
      "Sample: [2.9 121.0 6.0 0.5 0.1 3.6 230.0 235.0 139.0 3.1 'Rawah' 'ELU-4744']\n",
      "\tPredicted class: Lodgepole_Pine\n",
      "\tTrue class: Lodgepole_Pine\n",
      "Sample: [3.2 155.0 15.0 0.2 0.0 0.4 237.0 240.0 129.0 2.3 'Neota' 'ELU-4758']\n",
      "\tPredicted class: Spruce/Fir\n",
      "\tTrue class: Spruce/Fir\n",
      "Sample: [3.0 330.0 8.0 0.1 0.0 2.6 201.0 231.0 169.0 6.2 'Rawah' 'ELU-7745']\n",
      "\tPredicted class: Lodgepole_Pine\n",
      "\tTrue class: Spruce/Fir\n"
     ]
    }
   ],
   "source": [
    "# Initialise the classifier, requiring the decision tree to have no more than 5 levels\n",
    "classifier = DecisionTree(max_depth = 4)\n",
    "# Fit the classifier to the training data\n",
    "classifier.fit(X_cd_train, y_cd_train)\n",
    "\n",
    "# Predict the classification for some samples to the testing set\n",
    "for (sample, prediction, truth) in zip(X_cd_test[3:10], classifier.predict(X_cd_test[3:10]), y_cd_test[3:10]):\n",
    "    # Print the sample, predicted class and ground truth\n",
    "    print(\"Sample: {}\\n\\tPredicted class: {}\\n\\tTrue class: {}\".format(sample, prediction, truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation and analysis\n",
    "\n",
    "Executing all the cells from the previous section correctly only means that your implementation of [kNN classifier](#knn-Classifier) and [Decision Tree classifier](#Decision-Tree-classifier) runs on the provided data. This has still not provided any insight on how well those models represent the data.\n",
    "\n",
    "In this section, you are instead required to calculate some evaluation metrics, and evaluate the produced models on the whole of the held-out data (test set) defined in the [Dataset](#Dataset) section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1 - Evaluation\n",
    "#### 10% marks\n",
    "\n",
    "You are required to write a function that will calculate different evaluation metrics based on the ground truth labels and the predicted labels. Specifically, write a function:\n",
    "- `evaluate(y_true, y_pred)`: evaluate classification results\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `y_true` : Ground truth labels for $n$ samples. This is either a list of $n$ elements, or a `numpy.array` of dimensions `(n,)`\n",
    "    `y_pred` : Predicted labels for $n$ samples. This is either a list of $n$ elements, or a `numpy.array` of dimensions `(n,)`\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    A touple `(a, p, r, k)` consisting of the following values:\n",
    "    - `a` : overall accuracy of the predictions\n",
    "    - `p` : a dictionary containing a precision score for each class present in `y_true`\n",
    "    - `r` : a dictionary containing a recall score for each class present in `y_true`\n",
    "    - `k` : Cohen's Kappa metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    pre = precision_score(y_true, y_pred, average = None, labels = np.unique(y_true), zero_division = 1) # Stops division...\n",
    "    rec = recall_score(y_true, y_pred, average = None, labels = np.unique(y_true), zero_division = 1) # ... by zero!\n",
    "    cKappa = cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    # Create a dicionary for precision and recall\n",
    "    precision = dict(zip(np.unique(y_true), pre))\n",
    "    recall = dict(zip(np.unique(y_true), rec))\n",
    "    \n",
    "    output = [acc, precision, recall, cKappa]\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell evaluates your implementation of [kNN classifier](#Task-2.2---kNN-classifier) and [Decision Tree classifier](#Task-3.2---Decision-Tree-classifier) on the numerical dataset defined in the [Dataset](#Dataset) section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating numerical dataset, using kNN:\n",
      "Accuracy = 0.5833, Cohen's Kappa = 0.3651\n",
      "\tClass monoclinic: precision = 0.56, recall = 0.62\n",
      "\tClass orthorhombic: precision = 0.67, recall = 0.60\n",
      "\tClass triclinic: precision = 0.50, recall = 0.50\n",
      "Evaluating numerical dataset, using DecisionTree:\n",
      "Accuracy = 0.3333, Cohen's Kappa = 0.0000\n",
      "\tClass monoclinic: precision = 0.33, recall = 1.00\n",
      "\tClass orthorhombic: precision = 1.00, recall = 0.00\n",
      "\tClass triclinic: precision = 1.00, recall = 0.00\n"
     ]
    }
   ],
   "source": [
    "classifier_knn = knn(k=5)\n",
    "classifier_knn.fit(X_nd_train, y_nd_train)\n",
    "\n",
    "classifier_dt = DecisionTree(min_samples_per_node = 3)\n",
    "classifier_dt.fit(X_nd_train, y_nd_train)\n",
    "\n",
    "y_knn = classifier_knn.predict(X_nd_test)\n",
    "y_dt = classifier_dt.predict(X_nd_test)\n",
    "\n",
    "a_knn, p_knn, r_knn, k_knn = evaluate(y_nd_test, y_knn)\n",
    "a_dt, p_dt, r_dt, k_dt = evaluate(y_nd_test, y_dt)\n",
    "\n",
    "print(\"Evaluating numerical dataset, using kNN:\")\n",
    "print(\"Accuracy = {:.4f}, Cohen's Kappa = {:.4f}\".format(a_knn, k_knn))\n",
    "for key in p_knn.keys():\n",
    "    print(\"\\tClass {}: precision = {:.2f}, recall = {:.2f}\".format(key, p_knn[key], r_knn[key]))\n",
    "\n",
    "print(\"Evaluating numerical dataset, using DecisionTree:\")\n",
    "print(\"Accuracy = {:.4f}, Cohen's Kappa = {:.4f}\".format(a_dt, k_dt))\n",
    "for key in p_dt.keys():\n",
    "    print(\"\\tClass {}: precision = {:.2f}, recall = {:.2f}\".format(key, p_dt[key], r_dt[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell evaluates your implementation of [Decision Tree classifier](#Decision-Tree-classifier) on the [dataset containing a mixture of numerical and categorical data](#Categorical-data):\n",
    "\n",
    "_**Warning:**_ Executing this cell may take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating categorical dataset, using DecisionTree:\n",
      "Accuracy = 0.6987, Cohen's Kappa = 0.5061\n",
      "\tClass Aspen: precision = 1.00, recall = 0.00\n",
      "\tClass Cottonwood/Willow: precision = 1.00, recall = 0.00\n",
      "\tClass Douglas-fir: precision = 0.46, recall = 0.05\n",
      "\tClass Krummholz: precision = 0.68, recall = 0.52\n",
      "\tClass Lodgepole_Pine: precision = 0.74, recall = 0.75\n",
      "\tClass Ponderosa_Pine: precision = 0.64, recall = 0.86\n",
      "\tClass Spruce/Fir: precision = 0.67, recall = 0.71\n"
     ]
    }
   ],
   "source": [
    "classifier_categorical = DecisionTree(max_depth = 4)\n",
    "classifier_categorical.fit(X_cd_train, y_cd_train)\n",
    "\n",
    "y_cd_pred = classifier_categorical.predict(X_cd_test)\n",
    "a_cat, p_cat, r_cat, k_cat = evaluate(y_cd_test, y_cd_pred)\n",
    "\n",
    "print(\"Evaluating categorical dataset, using DecisionTree:\")\n",
    "print(\"Accuracy = {:.4f}, Cohen's Kappa = {:.4f}\".format(a_cat, k_cat))\n",
    "for key in p_cat.keys():\n",
    "    print(\"\\tClass {}: precision = {:.2f}, recall = {:.2f}\".format(key, p_cat[key], r_cat[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2 - Analysis\n",
    "#### 10% marks\n",
    "\n",
    "Answer the following questions in the space provided below (marked as **YOUR ANSWERS**):\n",
    "1. Explain the difference between the different performance metrics calculated for [Task 4.1](#Task-4.1---Evaluation). Which additional metrics could you propose to evaluate the performance of the defined models? Which of the calculated metrics would you chose to report, and why, for the analysis of the two [datasets](#Datasets) used in this assessment?\n",
    "\n",
    "2. In case you were handling a _very large_ amount of data, which of the models do you expect to be larger (i.e. take up more memory)? Which of the models do you expect to train faster? Which of the models do you expect to reach a decision faster? Explain and justify your answers.\n",
    "\n",
    "3. When handling numerical data, what is the role of normalisation? The numerical data used in this assessment was not normalised. If you were to normalise the data before training these classification models, would either of them change how they represent the data (and potentially return different results)?\n",
    "\n",
    "4. For evaluating the performance of the classifiers implemented for this assignment, $80\\%$ of the data was used for training the models, and $20\\%$ for testing. What are the shortcomings of this evaluation strategy, and can you propose and describe a better one?\n",
    "\n",
    "_Note:_ You may use the cell marked as **EXPERIMENTAL CELL** to write any code that could help you answer the above questions, or in general, to experiment with the code produced for this assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTAL CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ You may use this cell to write any code which may help you answers the questions above ##############\n",
    "####### Your implementations from this cell will not be assessed, feel free to use it for experimentation ########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOUR ANSWERS:\n",
    "\n",
    "1. <font color='black'>Accuracy measures the proportion of correct predictions out of the total predictions made by a model. It is often used as a way to evaluate the performance of a classification model. Precision measures the proportion of true-positive predictions out of all positive predictions made by a model and can be used to evaluate a model's ability to return only relevant results. Recall, also known as true-positive rate, measures the proportion of true-positive predictions out of all actual positive cases and evaluates a model's ability to find all relevant cases. Cohen's Kappa is a metric that compares the observed accuracy of a model to the accuracy that would be expected by chance. It can be used to evaluate the agreement between two raters and classification models, particularly when the classes are imbalanced. It varies between -1 to 1 with -1 showing completely different agreement to 1 showing perfect agreement. \n",
    "    \n",
    "    One alternate metric would be Receiver Operating Characteristic (ROC) and Area Under the ROC Curve (AUC-ROC). ROC is a plot of true-positive rate against the false positive rate and AUC-ROC is the area under the ROC curve. ROC and AUC-ROC evaluate the performance particularly when the class distribution is imbalanced. Another metric which could have been used is a confusion matrix, which is a table that is used to define true-positive, true-negative, false-positive and false-negatives for the model. The F1 score is another metric which is the harmonic mean of precision and recall and is often used for imbalanced classes too. Linked with the confusion matrix, specificity is a metric which could have been used to measure the proportion of true-negative predictions out of all actual negative cases.\n",
    "\n",
    "    As both datasets have imbalanced classes (the proportion is not equal) Cohen's Kappa would be the best metric. It manages to overcome this limitation by considering the proportion of agreement that occurs by chance. This can be calculated by comparing the proportion of correct predictions (true-positives and true-negatives) with the proportion of correct predictions that would be expected by chance, given the class distribution; it takes into account the different frequencies of the classes, giving a more balanced view of how the classifier is performing across different classes.</font> \n",
    "2. <font color='black'>Decision Tree models typically require more memory than KNN models because they build an internal tree structure during the training phase, which can take up a significant amount of memory. The amount of memory required to store the tree structure increases with the number of training examples and the number of features, which means that Decision Tree models may become memory-intensive when handling large datasets.\n",
    "\n",
    "    Decision Tree models typically train faster than KNN models, especially when dealing with large datasets. This is because the prediction time of the KNN model is linear in the number of instances in the dataset, so if you have a large dataset with many instances, the KNN model may be slow to predict.\n",
    "\n",
    "    A Decision Tree model would reach a decision faster than a KNN model when handling a lot of data as KNN models use the entire dataset to make predictions, so the time required to make a prediction increases with the size of the dataset. It performs a euclidean distance calculation for every instance in the dataset to find the k nearest neighbours, which can be slow when handling a lot of data. On the other hand, Decision Tree models partition the feature space into smaller regions, and the prediction is made based on the region in which the new instance falls. This can make the prediction process much faster, especially when the tree is not deep and the instances are well separated by the feature space.</font> \n",
    "3. <font color='black'>\"Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information\" [2].\n",
    "\n",
    "    When training a KNN model, normalising the data can have an impact on the model's performance because the Euclidean distance calculation is sensitive to the scale of the features. By normalising the data, the features are scaled to have the same range, which can help to reduce the impact of features with a larger scale. However, decision trees can handle categorical and numerical values and can find the best splits without the need for normalisation. Both the training sets and test sets should be normalised to make sure that the model is trained on the same distribution as the data it will be used to predict.</font> \n",
    "4. <font color='black'>One shortcoming of an 80/20 test split is overfitting. As we are working with a relatively small dataset, by reserving only 20% of the data for testing, the test set may not have much class variance within it. This would generate poor generalisation and the model's performance on the under-represented class may not be representative of real-world performance.\n",
    "\n",
    "    A different strategy that I would propose would be K-fold cross-validation. By splitting the dataset into K number of chunks and using the whole dataset for the training phase and testing phase, it not only makes better use of the data but reduces the risk of overfitting too. \"For smaller datasets, each observation is extremely valuable, and we can’t spare any for validation. [...]. This method is computationally expensive. Yet it offers an effective model evaluation over a small dataset by training multiple models.\" [https://www.baeldung.com/cs/train-test-datasets-ratio].</font>\n",
    "\n",
    "\n",
    "REFERENCES:\n",
    "\n",
    "    [1] -  AssemblyAI-Examples (2022). Machine-Learning-From-Scratch/04 Decision Trees at main · AssemblyAI-Examples/Machine-Learning-From-Scratch. [online] GitHub. Available at: https://github.com/AssemblyAI-Examples/Machine-Learning-From-Scratch/tree/main/04%20Decision%20Trees [Accessed 20 Dec. 2022].\n",
    "    \n",
    "    [2] - likebupt (n.d.). Partition and Sample: Component reference - Azure Machine Learning. [online] learn.microsoft.com. Available at: https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/partition-and-sample [Accessed 5 Jan. 2023].\n",
    "    \n",
    "    [3] - Tokuç, A.A. (2021). Splitting a Dataset into Train and Test Sets | Baeldung on Computer Science. [online] www.baeldung.com. Available at: https://www.baeldung.com/cs/train-test-datasets-ratio [Accessed 5 Jan. 2023]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
